{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINDS THE TRAINING MATRIX X WITH CLASS k\n",
    "\n",
    "def preEstimation(X,y,k):\n",
    "    # Input:  Matrix of training examples X.\n",
    "    #         Vector of labels y.\n",
    "    #         Class k.\n",
    "    # Output: Matrix of training examples X of certain class y = k.\n",
    "    #         Vector of levels y with class equal to k.\n",
    "    \n",
    "    X = np.row_stack((X,y))\n",
    "    tmp = X[:,X[X.shape[0]-1,:]==k]    \n",
    "    X_class = tmp[:tmp.shape[0]-1,:]\n",
    "    y_class = np.array([y[y[:]==k]])    \n",
    "    \n",
    "    return X_class, y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMPUTES THE MEAN OF EACH COMPONENT OF x FOR THE WHOLE SET OF SIZE m.\n",
    "\n",
    "def meanEstim(X):\n",
    "    # Input:  Matrix of training examples X of certain class y.\n",
    "    # Output: Mean vector of the training examples X of certain class y.\n",
    "     \n",
    "    u = np.sum(X,axis=1,keepdims=True)\n",
    "    u = u / X.shape[1]\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CALCULATES THE COVARIANCE OF EACH COMPONENT OF x FOR THE WHOLE SET OF SIZE m.\n",
    "\n",
    "def varEstim(X):\n",
    "    # Input:  Matrix of training examples X of certain class y.\n",
    "    # Output: Covariance matrix of the training examples X.\n",
    "    \n",
    "    S = np.zeros((X.shape[0],X.shape[0]))\n",
    "    \n",
    "    X = X - meanEstim(X)\n",
    "    \n",
    "    for i in range(0,X.shape[1]):\n",
    "        x = X[:,i].reshape(X.shape[0],1)\n",
    "        S = S + np.dot(x,x.T)\n",
    "    \n",
    "    S = S / (X.shape[1]-1)\n",
    "    \n",
    "    V = np.diag(np.diagonal(S))\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMPUTES THE PROBABILITY OF y BEING EQUAL TO k ACCORDING TO A BERNOULLI DISTRIBUTION.\n",
    "\n",
    "def bernouEstim(y,m):\n",
    "    # Input:  Vector of labels y.\n",
    "    #         Size of the training set.\n",
    "    # Output: Probability of P(y=k) given a Bernoulli distribution.\n",
    "    \n",
    "    o = y.shape[1] / m\n",
    "    \n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ESTIMATES THE MEAN VECTOR, THE COVARIANCE MATRIX AND P(y) FOR EACH CLASS k.\n",
    "\n",
    "def NaiveBayesEstimation(X,y,K):\n",
    "    # Input:  Matrix of training examples X.\n",
    "    #         Vector of labels y.\n",
    "    #         Number of classes k.\n",
    "    # Output: Naive Bayes estimation of the mean vector u, covariance matrix S and P(y) for each class k.\n",
    "    \n",
    "    estimations = []\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    for i in range(K):\n",
    "        X_pre, y_pre = preEstimation(X,y,i)\n",
    "        \n",
    "        u = meanEstim(X_pre)\n",
    "        V = varEstim(X_pre)\n",
    "        o = bernouEstim(y_pre,m)\n",
    "        \n",
    "        estimations.append({\"Mean\": u,\"Variance\": V,\"Bernoulli\": o})\n",
    "    \n",
    "    return estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GaussianLikelihood(X):\n",
    "    u = meanEstim(X)\n",
    "    v = varEstim(X)\n",
    "    return (1/np.sqrt(2*np.pi*v))*np.exp(-(np.multiply((X-u),(X-u))/(2*v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THE FUNCTION CLASSIFIES THE TEST/VALIDATION EXAMPLES.\n",
    "\n",
    "def classificatorNaiveBayes(X,estimations,K):\n",
    "    # Input:  Matrix of test examples X.\n",
    "    #         List with the estimations of the mean vector, covariance matrix and P(y) for each class k.\n",
    "    #         Number of classes k.\n",
    "    # Output: Vector of LDA predicted labels y.\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(K):\n",
    "        u = estimations[i]['Mean']\n",
    "        S = estimations[i]['Variance']\n",
    "        o = estimations[i]['Bernoulli']\n",
    "        \n",
    "        A = - np.array([np.diagonal((np.dot(np.dot(X.T,np.linalg.inv(S)),X)))])/2\n",
    "        B = np.dot(np.dot(u.T,np.linalg.inv(S)),X) - (np.dot(np.dot(u.T,np.linalg.inv(S)),u))/2\n",
    "        C = np.log(o) - (np.log(np.abs(np.linalg.det(S))))/2\n",
    "        \n",
    "        cost = A + B + C\n",
    "        costs.append(cost)\n",
    "        \n",
    "    costs = np.array(costs)\n",
    "    y_predict = np.argmax(costs,axis=0)\n",
    "    \n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FUNCTION GIVES DIFFERENT EVALUATION METRICS.\n",
    "\n",
    "def evalModelNaiveBayes(y_predicted,y_gt):\n",
    "    # Input:  Vector of Logistic Regression labels Y predicted.\n",
    "    #         Vector of labels Y.\n",
    "    # Output: Precision of the results.\n",
    "    #         Recall of the results.\n",
    "    #         F1 of the results.\n",
    "    #         Accuracy of the results.\n",
    "    \n",
    "    TP = (y_predicted * y_gt == 1).sum()\n",
    "    FP = (y_predicted - y_gt == 1).sum()\n",
    "    TN = (y_predicted + y_gt == 0).sum()\n",
    "    FN = (y_predicted - y_gt == -1).sum()\n",
    "    \n",
    "    Precision = np.round((TP/(TP+FP))*100,decimals=2)\n",
    "    Recall = np.round((TP/(TP+FN))*100,decimals=2)\n",
    "    F1 = np.round(2/((1/Precision)+(1/Recall)),decimals=2)\n",
    "    Accuracy = np.round(((TP+TN)/(TP+TN+FP+FN))*100,decimals=2)\n",
    "    \n",
    "    return Precision, Recall, F1, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
